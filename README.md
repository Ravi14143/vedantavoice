
# ğŸ™ï¸ Vedanta Voice

**Vedanta Voice** is an interactive AI chatbot that allows users to ask questions related to Vedantic knowledge (e.g., Bhagavad Gita) and receive contextual, multilingual answers.  
It uses **LangChain**, **FAISS**, **HuggingFace embeddings**, and **Llama 2** (via CTransformers) for retrieval-based question answering, integrated with **Streamlit** for the user interface.

---

## ğŸ§© Features

- ğŸ§  **Retrieval-based QA** using FAISS and LangChain  
- ğŸ’¬ **Conversational chat interface** built with Streamlit  
- ğŸŒ **Automatic language detection and translation** via Google Translate  
- ğŸ“š **PDF context retrieval** â€” answers sourced from uploaded PDFs  
- ğŸ”— **Source document linking** displayed with each response  
- ğŸ—£ï¸ (Optional) **Text-to-speech integration** (commented out, ready for use)

---

## âš™ï¸ Tech Stack

- **Python 3.9+**
- **Streamlit**
- **LangChain**
- **FAISS**
- **HuggingFace Sentence Transformers**
- **CTransformers (Llama 2)**
- **Googletrans**
- **Langdetect**
- **Streamlit Chat**

---

## ğŸ—ï¸ Installation

### 1. Clone the repository
```bash
git clone <your-repo-url>
cd vedanta-voice
````

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Run the App

```bash
streamlit run app.py
```

Then open the local URL shown in your terminal â€” typically
ğŸ‘‰ **[http://localhost:8501](http://localhost:8501)**

---

## ğŸ“ Project Structure

```
vedanta-voice/
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/           # FAISS vector database
â”œâ”€â”€ vedanta_voice.py        # Main Streamlit app
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§­ How It Works

1. **FAISS Vector DB** stores embeddings of your PDFs.
2. **User asks a question** â†’ language detected â†’ translated to English.
3. **Retriever** searches relevant chunks from FAISS DB.
4. **Llama 2 model** generates a context-aware response.
5. **Response** is translated back to the userâ€™s language (if needed).
6. **Sources** of the answer are displayed and linked.

---

## ğŸ—£ï¸ Optional Voice Features

Commented code is already included for:

* **Speech generation (WhisperSpeech / pyttsx3)**
* **Audio playback of generated responses**

You can enable these by installing the relevant libraries and uncommenting those sections.

---

## âš ï¸ Notes

* Make sure your **FAISS database path** matches `DB_FAISS_PATH = 'vectorstore/db_faiss/'`
* The model `"TheBloke/Llama-2-7B-Chat-GGML"` must be downloaded or accessible locally.
* Google Translate API via `googletrans` may occasionally be rate-limited.

---

```
```
